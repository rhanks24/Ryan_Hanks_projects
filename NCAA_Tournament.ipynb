{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e7c4ca",
   "metadata": {},
   "source": [
    "**Project Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a4586",
   "metadata": {},
   "source": [
    "*This notebook is meant to be run start to finish one time (without jumping around) to ensure that everything runs correctly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d833e9",
   "metadata": {},
   "source": [
    "The first step is to run the .py file that contains all of the dataframes that we need to access in this notebook. The use of this file is to remove the \"gross\" data manipulation from the final notebook, and pull the data straight from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7439cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Project_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43e22c",
   "metadata": {},
   "source": [
    "These imports are very necessary for all of the modeling that we will be doing in this notebook. The main library we are using is sklearn, which contains a lot of useful tools for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e3eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import time\n",
    "from sklearn.datasets import make_circles\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4610ca8",
   "metadata": {},
   "source": [
    "This is the creation of our training vectors and labels. The dataframe called 'final' is pulled from the .py file and includes all of the training data that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7286ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = final.drop(columns = ['WIN'])\n",
    "train_labels = final['WIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939b8e8",
   "metadata": {},
   "source": [
    "We then used this SVC model training from class to obtain the correct parameters for our model to be most effective during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0095262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=10.0, class_weight='balanced', gamma=0.005)\n",
      "Best parameters found by grid search:\n",
      "{'C': 10.0, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "Runtime 4.274148464202881\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tmp_vectors = train_vectors\n",
    "tmp_labels = train_labels\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "param_grid = {'C': [1e1, 5e1, 1e2, 5e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "              'kernel': ['rbf']}\n",
    "clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "\n",
    "clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6babc",
   "metadata": {},
   "source": [
    "Now, it is time to use our model to test on the 2021 March Madness bracket..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd90369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict21 = clf.predict(final21)\n",
    "predict21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a956ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true21 = (predict21 == result21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d873cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(true21)/63"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cf54f",
   "metadata": {},
   "source": [
    "We compared the predicted result of the games to the actual result of the games pulled from the .py file. The number displayed above is the proportion of games our model predicted correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602aa6eb",
   "metadata": {},
   "source": [
    "It is time to test how the accuracy of our model looks over time. The following code is a loop that runs 100 iterations of the a training/testing split and calculates the accuracy of the model each iteration. The results are stored in a list that will be used to find the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197a68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "i = 0\n",
    "while i < 100:\n",
    "    train_vectors, test_vectors, train_labels, test_labels = train_test_split(final.drop(columns = ['WIN']), final['WIN'], test_size = 0.25)\n",
    "    \n",
    "    tmp_vectors = train_vectors\n",
    "    tmp_labels = train_labels\n",
    "\n",
    "    param_grid = {'C': [1e1, 5e1],\n",
    "                  'gamma': [0.001, 0.005, 0.01],\n",
    "                  'kernel': ['rbf']}\n",
    "    clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "\n",
    "    clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "    \n",
    "    predict_vectors = test_vectors\n",
    "    true_labels = test_labels\n",
    "    \n",
    "    pred_labels = clf.predict(predict_vectors)\n",
    "    \n",
    "    accuracy.append(clf.score(predict_vectors, true_labels))\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "443de698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6849367088607594"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b1b97",
   "metadata": {},
   "source": [
    "Now, we want to understand how a model would predict the 2021 March Madness bracket if we used both teams statistics in the same row of a datafram, as opposed to taking the difference in the statistics. We used the combined dataframe pulled from the .py file to run this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280c2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = combined.drop(columns = ['WIN'])\n",
    "train_labels = combined['WIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782101cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVC(C=10.0, class_weight='balanced', gamma=0.05)\n",
      "Best parameters found by grid search:\n",
      "{'C': 10.0, 'gamma': 0.05, 'kernel': 'rbf'}\n",
      "Runtime 2.83632493019104\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tmp_vectors = train_vectors\n",
    "tmp_labels = train_labels\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "param_grid = {'C': [1e1, 5e1, 1e2, 5e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "              'kernel': ['rbf']}\n",
    "clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "\n",
    "clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d72bcef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict21 = clf.predict(combined21)\n",
    "predict21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6933989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true21 = (predict21 == result21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4082db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6984126984126984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(true21)/63"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ee20f",
   "metadata": {},
   "source": [
    "We can see that using the combined dataframe results in a little bit worse of a prediction for the 2021 March Madness bracket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed331f1",
   "metadata": {},
   "source": [
    "But we do want to see the accuracy of this model over time, and how it stacks up against the previous model that uses a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "046e058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "i = 0\n",
    "while i < 100:\n",
    "    train_vectors, test_vectors, train_labels, test_labels = train_test_split(combined.drop(columns = ['WIN']), combined['WIN'], test_size = 0.25)\n",
    "    \n",
    "    tmp_vectors = train_vectors\n",
    "    tmp_labels = train_labels\n",
    "\n",
    "    param_grid = {'C': [1e1, 5e1],\n",
    "                  'gamma': [0.001, 0.005, 0.01],\n",
    "                  'kernel': ['rbf']}\n",
    "    clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "\n",
    "    clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "    \n",
    "    predict_vectors = test_vectors\n",
    "    true_labels = test_labels\n",
    "    \n",
    "    pred_labels = clf.predict(predict_vectors)\n",
    "    \n",
    "    accuracy.append(clf.score(predict_vectors, true_labels))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d907fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6858227848101264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1a336",
   "metadata": {},
   "source": [
    "We find that both of these models are fairly similar in accuracy when predicting the outcome of March Madness games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a117f",
   "metadata": {},
   "source": [
    "The following code utilizes logistic fitting to observe which features have the most significance when predicting the outcomes of these games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaeae3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.453724\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    WIN   No. Observations:                  315\n",
      "Model:                          Logit   Df Residuals:                      296\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Sun, 04 Dec 2022   Pseudo R-squ.:                  0.2589\n",
      "Time:                        19:22:18   Log-Likelihood:                -142.92\n",
      "converged:                       True   LL-Null:                       -192.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.368e-13\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2434      0.285      0.854      0.393      -0.315       0.802\n",
      "ADJOE          0.3984      0.089      4.461      0.000       0.223       0.573\n",
      "ADJDE         -0.3429      0.114     -3.007      0.003      -0.566      -0.119\n",
      "BARTHAG      -10.9367      4.453     -2.456      0.014     -19.665      -2.208\n",
      "EFG_O         -0.3617      0.528     -0.684      0.494      -1.398       0.674\n",
      "EFG_D         -0.3742      0.526     -0.711      0.477      -1.406       0.657\n",
      "TOR            0.2178      0.114      1.917      0.055      -0.005       0.440\n",
      "TORD           0.0294      0.097      0.304      0.761      -0.160       0.219\n",
      "ORB           -0.0409      0.047     -0.874      0.382      -0.133       0.051\n",
      "DRB            0.0665      0.058      1.141      0.254      -0.048       0.181\n",
      "FTR           -0.0413      0.029     -1.420      0.156      -0.098       0.016\n",
      "FTRD          -0.0316      0.029     -1.103      0.270      -0.088       0.024\n",
      "2P_O           0.2126      0.339      0.627      0.531      -0.452       0.878\n",
      "2P_D           0.2862      0.340      0.842      0.400      -0.380       0.953\n",
      "3P_O           0.1142      0.268      0.427      0.669      -0.410       0.639\n",
      "3P_D           0.2500      0.266      0.938      0.348      -0.272       0.772\n",
      "ADJ_T         -0.0718      0.045     -1.586      0.113      -0.160       0.017\n",
      "WAB            0.1396      0.082      1.705      0.088      -0.021       0.300\n",
      "SEED           0.2572      0.086      2.995      0.003       0.089       0.425\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "train_vectors = final.drop(columns = ['WIN'])\n",
    "train_labels = final['WIN']\n",
    "\n",
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_vectors))\n",
    "result = logit_model.fit()\n",
    "print(result.summary() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6eced57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.419954\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    WIN   No. Observations:                  315\n",
      "Model:                          Logit   Df Residuals:                      278\n",
      "Method:                           MLE   Df Model:                           36\n",
      "Date:                Sun, 04 Dec 2022   Pseudo R-squ.:                  0.3140\n",
      "Time:                        19:22:44   Log-Likelihood:                -132.29\n",
      "converged:                       True   LL-Null:                       -192.84\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.847e-11\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.1279     22.382     -0.453      0.651     -53.996      33.740\n",
      "ADJOE          0.4299      0.171      2.514      0.012       0.095       0.765\n",
      "ADJDE         -0.4208      0.212     -1.980      0.048      -0.837      -0.004\n",
      "BARTHAG      -12.0886     18.001     -0.672      0.502     -47.370      23.193\n",
      "EFG_O         -0.3702      0.746     -0.496      0.620      -1.833       1.092\n",
      "EFG_D         -2.0015      0.843     -2.374      0.018      -3.654      -0.349\n",
      "TOR            0.2204      0.170      1.296      0.195      -0.113       0.554\n",
      "TORD           0.0064      0.153      0.042      0.967      -0.293       0.306\n",
      "ORB           -0.0387      0.079     -0.489      0.625      -0.194       0.117\n",
      "DRB            0.1416      0.096      1.474      0.141      -0.047       0.330\n",
      "FTR           -0.0673      0.045     -1.512      0.131      -0.155       0.020\n",
      "FTRD          -0.0539      0.044     -1.225      0.220      -0.140       0.032\n",
      "2P_O           0.2875      0.473      0.608      0.543      -0.639       1.214\n",
      "2P_D           1.4343      0.552      2.599      0.009       0.353       2.516\n",
      "3P_O           0.0657      0.377      0.174      0.862      -0.673       0.805\n",
      "3P_D           1.1937      0.438      2.725      0.006       0.335       2.052\n",
      "ADJ_T         -0.0904      0.060     -1.503      0.133      -0.208       0.028\n",
      "WAB            0.2030      0.127      1.594      0.111      -0.047       0.453\n",
      "SEED           0.4157      0.152      2.730      0.006       0.117       0.714\n",
      "W_ADJOE       -0.4875      0.127     -3.851      0.000      -0.736      -0.239\n",
      "W_ADJDE        0.4365      0.181      2.411      0.016       0.082       0.791\n",
      "W_BARTHAG     16.4675      6.013      2.739      0.006       4.683      28.252\n",
      "W_EFG_O        0.0333      0.816      0.041      0.967      -1.566       1.633\n",
      "W_EFG_D       -0.9576      0.807     -1.187      0.235      -2.539       0.623\n",
      "W_TOR         -0.2396      0.171     -1.397      0.162      -0.576       0.096\n",
      "W_TORD        -0.0207      0.144     -0.144      0.886      -0.303       0.261\n",
      "W_ORB          0.0257      0.071      0.361      0.718      -0.114       0.165\n",
      "W_DRB          0.0135      0.090      0.150      0.881      -0.163       0.190\n",
      "W_FTR          0.0173      0.039      0.438      0.661      -0.060       0.095\n",
      "W_FTRD         0.0156      0.038      0.405      0.685      -0.060       0.091\n",
      "W_2P_O         0.0713      0.535      0.133      0.894      -0.978       1.121\n",
      "W_2P_D         0.6257      0.519      1.205      0.228      -0.392       1.644\n",
      "W_3P_O        -0.0078      0.420     -0.019      0.985      -0.832       0.816\n",
      "W_3P_D         0.5179      0.395      1.310      0.190      -0.257       1.293\n",
      "W_ADJ_T        0.0445      0.067      0.667      0.505      -0.086       0.175\n",
      "W_WAB         -0.2903      0.136     -2.129      0.033      -0.557      -0.023\n",
      "W_SEED        -0.3630      0.127     -2.860      0.004      -0.612      -0.114\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "train_vectors = combined.drop(columns = ['WIN'])\n",
    "train_labels = combined['WIN']\n",
    "\n",
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_vectors))\n",
    "result = logit_model.fit()\n",
    "print(result.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e889bed",
   "metadata": {},
   "source": [
    "To conclude these two models, we see that there are many features that are very significant, as well as many features that have very little significance. The interesting part of this is that when doing SVC modeling with the exclusion of the insignificant features, the model accuracy become worse. Below is a small example of this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37cb45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "i = 0\n",
    "while i < 100:\n",
    "    train_vectors, test_vectors, train_labels, test_labels = train_test_split(final.drop(columns = ['WIN', 'EFG_O', 'EFG_D', 'TORD', '2P_O', '2P_D', '3P_O', '3P_D']), final['WIN'], test_size = 0.25)\n",
    "    \n",
    "    tmp_vectors = train_vectors\n",
    "    tmp_labels = train_labels\n",
    "\n",
    "    param_grid = {'C': [1e1, 5e1],\n",
    "                  'gamma': [0.001, 0.005, 0.01],\n",
    "                  'kernel': ['rbf']}\n",
    "    clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "\n",
    "    clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "    \n",
    "    predict_vectors = test_vectors\n",
    "    true_labels = test_labels\n",
    "    \n",
    "    pred_labels = clf.predict(predict_vectors)\n",
    "    \n",
    "    accuracy.append(clf.score(predict_vectors, true_labels))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e8a0470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6499999999999999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accuracy)/len(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c04e4",
   "metadata": {},
   "source": [
    "We see that the accuracy of this model decreases a small amount when excluding some of the insignificant features. We also performed various combinations of excluding features, but the best accuracy seems to always be the model that uses all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516e1d6",
   "metadata": {},
   "source": [
    "In conclusion, our initial model does a fairly good job at predicting the 2021 March Madness bracket. The accuracy is slighlty higher than if you were to simply pick the team with the better seed (which is promising). We want to be able to pick out the upsets and predict those because that is the main difficulty when predicting March Madness games. These models are fairly basic in the realm of sports prediciton, but it is a good display of the skills we have learned in class. It is important to note that the outcome of a sports game is not always correlated with the season statistics of the team. There are many other factors at hand. Humans are very hard to predict, especially in sports. We are streaky individuals, and this is really illuminated when looking at the results of basketball games. How do some 'worse' teams in March Madness make crazy runs in the tournament, and beat really good teams? Sometimes, we just do not know. Sometimes, their team statistics do not matter at all. With all of this information in mind, our model is a decent and cool prediction of the 2021 March Madness bracket."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
